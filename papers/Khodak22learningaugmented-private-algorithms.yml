title: Learning-Augmented Private Algorithms for Multiple Quantile Release
authors: Mikhail Khodak, Kareem Amin, Travis Dick, Sergei Vassilvitskii
abstract: When applying differential privacy to sensitive data, we can often improve performance using external information
  such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms
  with predictions) framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful
  way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve
  utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees
  that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent
  guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding
  robustness, and the provision of useful surrogate losses for two novel ``meta"algorithms that learn predictions from other
  (potentially sensitive) data. We conclude with experiments on challenging tasks demonstrating that learning predictions
  across one or more instances can lead to large error reductions while preserving privacy.
labels:
- differential privacy
- online
publications:
- name: arXiv
  url: http://arxiv.org/abs/2210.11222v2
  year: 2022
  month: 10
arxiv: 2210.11222
s2_id: 71cfe54cb46cb01fc9310c900c5adb74f0d2a306
year: 2022
