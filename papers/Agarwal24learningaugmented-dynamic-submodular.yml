title: Learning-Augmented Dynamic Submodular Maximization
authors: Arpit Agarwal, Eric Balkanski
abstract: 'In dynamic submodular maximization, the goal is to maintain a high-value solution over a sequence of element insertions
  and deletions with a fast update time. Motivated by large-scale applications and the fact that dynamic data often exhibits
  patterns, we ask the following question: can predictions be used to accelerate the update time of dynamic submodular maximization
  algorithms? We consider the model for dynamic algorithms with predictions where predictions regarding the insertion and
  deletion times of elements can be used for preprocessing. Our main result is an algorithm with an $O(poly(\log \eta, \log
  w, \log k))$ amortized update time over the sequence of updates that achieves a $1/2 - \epsilon$ approximation in expectation
  for dynamic monotone submodular maximization under a cardinality constraint $k$, where the prediction error $\eta$ is the
  number of elements that are not inserted and deleted within $w$ time steps of their predicted insertion and deletion times.
  This amortized update time is independent of the length of the stream and instead depends on the prediction error.'
labels:
- dynamic / data structure
- running time
- submodular maximization
publications:
- name: NeurIPS
  url: http://papers.nips.cc/paper_files/paper/2024/hash/19cdab1dee61d55158cf106244ceab08-Abstract-Conference.html
  year: 2024
  dblp_key: conf/nips/AgarwalB24
  bibtex: "@inproceedings{DBLP:conf/nips/AgarwalB24,\n  author       = {Arpit Agarwal and\n  Eric Balkanski},\n  title   \
    \     = {Learning-Augmented Dynamic Submodular Maximization},\n  booktitle    = {NeurIPS},\n  year         = {2024}\n\
    }\n"
- name: arXiv
  url: https://arxiv.org/abs/2311.13006
  year: 2023
  month: 11
  day: 21
year: 2024
s2_id: 941cf5fafb3012bc7804e188c9ccfd92bb7dfd3a
